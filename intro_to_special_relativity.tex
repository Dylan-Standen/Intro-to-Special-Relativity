\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath, amsthm, amssymb}
\usepackage{titling}
\setlength{\droptitle}{-2em}
\frenchspacing
\title{\textbf{Special Relativity: A (Very) Brief Introduction}}
\author{}
\date{}
\usepackage{parskip}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage{hyperref}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}[section]
\usepackage{tikz}
\usepackage{physics}

\begin{document}

\maketitle

\section{Introduction:}
This will serve as a basic introduction to the essential elements of special relativity necessary to fully understand QFT. I begin with the key postulates and mathematical structure used to describe Einstein’s very special theory,before heading into further topics such as Lorentz invariance and some EM theory.

Each topic will be kept self-contained and as brief as possible. Note that I will provide historical context for some of the things discussed in these notes. But, only where it is deemed interesting and insightful (by me).

\section{Minkowski Space:}
This section of the text will set the stage for quite literally everything to come. I shall quickly review the historical context behind this beautiful mathematical structure before looking (in)formally at its contents. 
\subsection{Hermann Minkowski:}

Hermann Minkowski is an interesting historical figure (check his wiki page) and was a prominent mind within mathematics and mathematical physics during the early 20th century. He was, funnily enough, a former tutor of Einstein at Zurich (with Einstein choosing to skip most of his mathematics lectures) and found it surprising that his former pupil, who was arguably bad at maths, was able to come up with such a profound theory using simple algebraic logic. Minkowski was the first to make Einstein's rules rigorous, turning his algebraic work into a fully geometric picture. Let us now review this topic. 



\subsection{Geometry and Spacetime:}

Before I begin, I should mention that I shall not cover curved spacetimes at all within this text. They are not needed to understand QFT and are only applicable if you were to look at theories defined on curved background geometries. \\

I shall now introduce you to some rather basic differential geometry that is required to fully understand special relativity in a way that is applicable to QFT. Let's begin. 

\subsubsection{Smooth Manifolds:}

In simple terms, a smooth (or differentiable) manifold is one that locally ``looks like" (technically, it must be locally homeomorphic to) $\mathbb{R}^n$ with enough structure to do calculus on. This means that continuous functions can be defined on it, such as tensor fields. Note, there is, of course, a very thorough topological definition that requires certain conditions, such as `second countable' and `Hausdorff', but I will act like a good  physicist and ignore the mathematicians' pleas for rigour.  \\

Given a smooth manifold $\mathcal{M}$, it is possible to define a generalisation of a tangent to a curve (which is a 1-dimensional vector space) via the following definition:

\fbox{\begin{minipage}{34em}
\begin{definition}
    For any $p \in \mathcal{M}$ the \textit{tangent space} at $p$, denoted $T_p\mathcal{M}$, is the set of all tangent vectors to $\mathcal{M}$.
\end{definition}\end{minipage}}

The tangent space naturally forms a real vector space, allowing us to take linear combinations and scalar multiples of tangent vectors. Tangent vectors can also be viewed as smooth linear operators that act on functions defined on $\mathcal{M}$ that are required to satisfy the Leibniz rule (I will ignore this). If I want to look at the tangent spaces $\forall \,p \in \mathcal{M}$, a natural object is the tangent bundle, 

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{Tangent bundle}, denoted $T\mathcal{M}$, is given by the disjoint union of the tangent spaces at all points \( p \in \mathcal{M} \), 
    \begin{equation*}
        T\mathcal{M} = \bigsqcup_{p\, \in \mathcal{M}} T_p\mathcal{M} \, .
     \end{equation*}
\end{definition}\end{minipage}}

Think of this as merely the set of all tangent vectors to the manifold. An element of \( T\mathcal{M} \) is a pair \( (p, X) \), where \( p \in \mathcal{M} \) and \( X \in T_p\mathcal{M} \) are vectors. As with any vector space, it has a dual; namely, the set of linear maps from the vector space to the base field (usually $\mathbb{R}$ or $\mathbb{C}$):

\fbox{\begin{minipage}{34em}
\begin{definition}
The \textit{cotangent space} at a point $p$ is the dual vector space to the tangent space at $p$, and is denoted $T^*_p\mathcal{M}$. An element of this space is a covector and is the map 
\begin{equation*}
    \omega: T_p\mathcal{M} \rightarrow \mathbb{R} \, (\text{usually, but can be different)}\, .
\end{equation*}
\end{definition}\end{minipage}}

In a similar fashion to our definition of the tangent bundle, define: 

\fbox{\begin{minipage}{34em}
\begin{definition}
The \textit{cotangent bundle} of a smooth manifold \( \mathcal{M} \), denoted \( T^*\mathcal{M} \), is the disjoint union of the cotangent spaces at all points \( p \in \mathcal{M} \),
\[
T^*\mathcal{M} = \bigsqcup_{p \in \mathcal{M}} T_p^*\mathcal{M}.
\]
An element of \( T^*\mathcal{M} \) is a pair \( (p, \omega) \), where \( p \in \mathcal{M} \) and \( \omega \in T_p^*\mathcal{M} \) is now a covector (or 1-form) at \( p \). A \textit{1-form field} on \( \mathcal{M} \) is a smooth section of the cotangent bundle.
\end{definition}\end{minipage}}

As I have now introduced both the tangent and cotangent bundles, I will now define what is meant by a tensor field and, more generally, the tensor bundle. First, recall that a vector field is simply the assignment of a vector to a specific point in space, hence the tensor field may be defined naturally as 

\fbox{\begin{minipage}{34em}
\begin{definition} 
Let \( \mathcal{M} \) be a smooth manifold. The \textit{tensor bundle} of type \((r, s)\) is 
\[
T^r_s \mathcal{M} := \underbrace{T^*\mathcal{M} \otimes \cdots T^*\mathcal{M}}_{r\ \text{times}} \otimes \underbrace{T\mathcal{M} \otimes \cdots \otimes T\mathcal{M}}_{s\ \text{times}} ,
\]
whose fibre (just a selection of the specific tangent and cotangent spaces) at \( p \in \mathcal{M} \) is the vector space of type \((r,s)\) tensors (a map from $r$ copies of $T^*_p\mathcal{M}$ and $s$ copies of $T_p\mathcal{M}$ to $\mathbb{R}$) over \( T_p\mathcal{M} \) and \( T_p^*\mathcal{M} \).
\end{definition}\end{minipage}}


With this, a \textit{tensor field} of type $(r,s)$ on \( \mathcal{M} \) is a smooth section (a choice of one element from each fibre varying smoothly with p) of \( T^r_{s} \mathcal{M} \), i.e. a smooth assignment
\[
p \mapsto T(p) \in T^r_{s} \mathcal{M}.
\]
Simple examples of tensor fields include scalar fields, $T^0_0\mathcal{M}$, and vector fields, $T^1_0 \mathcal{M}$. For our purposes, I shall only be concerned with tensor fields of, at most, type $(0,2)$ or $(2,0)$. \\

With these definitions, which will hopefully give you a sense of the underlying structure, the metric tensor can be defined via

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{metric tensor}, $g \, \in T^0_{2} \mathcal{M}$, must satisfy the following conditions:
    \begin{itemize}
        \item \textit{Symmetry} - Given $X,Y \, \in T_p\mathcal{M}$
        \begin{equation*}
            g(X,Y) = g(Y,X) \, .
        \end{equation*}
        \item \textit{Non-degeneracy} - Given $X,Y \, \in T_p\mathcal{M}$ 
        \begin{equation*}
            g(X,Y) = 0 \,, \forall \, \, Y \, \in T_p\mathcal{M} \iff X = 0 \, .
        \end{equation*}
    \end{itemize}
Non-degeneracy simply means that the only vector orthogonal to all others is the zero vector.  
\end{definition}\end{minipage}}


\subsubsection{The Minkowski metric:}

With these basic definitions I can now discuss Minkowski space proper. The thing that distinguishes Minkowski space from regular Euclidean 4-space, is the Minkowski metric.

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{Minkowski metric}, canonically denoted $\eta$, is a metric tensor of signature $(-, +,+,+)$ . In the standard orthonormal basis, its' components take the form
    \[
\eta_{\mu\nu}=\mathrm{diag}(-, +, +, +) = \mathrm{diag}(-1,1,1,1).
\]
\end{definition}\end{minipage}}

A manifold that has the above signature is called \textit{Lorentzian}. I have now ``rigorously'' defined everything needed to completely define Minkowski space:

\fbox{\begin{minipage}{34em}
\begin{definition}
    \textit{Minkowski space}, is the Lorentzian manifold $M = (\mathbb{R}^4, \eta$), where $\eta$ is the Minkowski metric. Since our manifold is flat, a global \textit{inertial coordinate} system may be chosen, such that $x \in M$ takes the form $x =(t,x^1,x^2,x^3)$. It is also common to write $M$ as $\mathbb{R}^{1,3}$.
\end{definition}\end{minipage}}

The differing sign means that the Minkowski metric is not positive definite ($>0$), like the Euclidean metric, but actually indefinite and has 3 distinct possibilities, depending on the sign of the inner product. As per usual, the inner product is defined via the metric tensor of the corresponding space, for example, in Euclidean space the inner product of two vectors, $v,w \in \mathbb{R}^n$ can be written as $\delta_{ij}v^i w^j$. The same may also be done in Minkowski space, where the indices are instead taken to be Greek (I assume you know Einstein's summation convention).  \\


This structure allows us to encode causality in a simple way. Given $X\in T_pM$ then:

\begin{itemize}
    \item If $\eta_{\mu\nu} X^\mu X^\nu >0$, then $X$ is said to be \textit{spacelike}.
    \item If $\eta_{\mu\nu} X^\mu X^\nu =0$, then $X$ is said to be \textit{null}.
    \item If $\eta_{\mu\nu} X^\mu X^\nu <0$, then $X$ is said to be \textit{timelike}.
\end{itemize}

\begin{figure}[h]
\centering
\begin{tikzpicture}[scale=1.15]
  % axes
  \draw[->] (-2.2,0) -- (2.2,0) node[below left] {$x$};
  \draw[->] (0,-2.5) -- (0,2.5) node[left] {$t$};

  % shaded cones (c = 1)
  \fill[blue!10]  (0,0) -- (2,2) -- (-2,2) -- cycle;   % future
  \fill[blue!10]   (0,0) -- (-2,-2) -- (2,-2) -- cycle; % past
\draw[->] (0,-2.5) -- (0,2.5) node[left] {$t$};

  % null lines
  \draw[thick] (-2,-2) -- (2,2) node[pos=0.7, above = 10] {$<0$};
  \draw[thick] (-2, 2) -- (2,-2) node[pos=0.85, above = 20pt] {$>0$};
  \draw[thick] (-2, 2) -- (2,-2) node[pos=0.25, below, sloped] {$=0$};

  

  % event at the origin
  \fill (0,0) circle (1.6pt) node[below left] {};
\end{tikzpicture}
\caption{Light cone in $1{+}1$ dimensions with $c=1$. Causal influence lies on or within the cone;
massless signals follow the null lines, i.e. move at $c$.}
\end{figure}



The metric also induces an isomorphism between the tangent space and its dual by ``raising'' and ``lowering'' indices, via 

\begin{equation*}
    X_\mu (\in T^*_pM) = \eta_{\mu \nu} X^{\nu} (\in T_pM) .
\end{equation*}

Define the inverse metric, written $\eta^{\mu \nu}$ via, 

\begin{equation*}
    \eta^{\mu \alpha} \eta_{\mu \beta} = \delta^\alpha_\beta\, ,
\end{equation*}

then notice that


\begin{equation*}
    X^\mu  = \eta^{\mu \nu} X_{\nu} \,.
\end{equation*}


As previously mentioned, a global orthonormal basis may be chosen such that $\eta$ takes the regular form. I am, of course, well within my right to choose a different basis for our space. This observation leads to the Lorentz group; which I shall now cover.

\subsection{The Lorentz Group:}

The Lorentz Group, named after Dutch physicist Hendrik Lorentz, actually predates special relativity. It was initially formulated as the set of transformations that leaves Maxwell's equations invariant under changes of frame. Einstein subsequently derived these transformations independently in his paper on special relativity. Minkowski was the first to define the group of all such transformations.\\

As a motivational example I shall look initially at $SO(n)$, before looking at the Lorentz group. Recall that $SO(n)$ is a subgroup of the \textit{isometry group} of $\mathbb{R}^n$, this means that the quadratic form is preserved. Namely, given the quadratic form

\begin{equation*}
    Q(v) = g(v,v) = v^\text{T}g \,v \,,
\end{equation*}

where $g$ is the metric, a linear operator $A$ is said to \textit{preserve} $Q$ iff 

\begin{equation*}
    Q(Av) = Q(v) \,
\end{equation*}

which implies that $A^\text{T}gA =g$. This is exactly the requirement for the matrix Lie group $O(n)$ (when $g = I)$. Think of these transformations as rotations; the vector's norm hasn't changed, it has simply been rotated. If I wish to preserve the orientation of the vector, i.e. no flips, I require only proper rotations. The group then becomes $SO(n)$ - the group of matrices in $O(n)$ with $\text{det} = 1$. \\


This is essentially exactly the case with Minkowski space, however, our space is not $\mathbb{R}^4$, it is $\mathbb{R}^{1,3}$. Thus, such a subgroup of the group of isometries for Minkowski space is often called the \textit{Pseudo-Orthogonal Group} or \textit{Lorentz group} and denoted $SO(1,3)$. Elements of this group are Lorentz transformations which satisfy

\begin{equation*}
    \Lambda^\text{T}\eta \Lambda = \eta\,.
\end{equation*}

There is also another nuance; time has a different sign to all other components in our space. In order to impose time orientation (since $\text{det} = 1$ imposes spatial orientation) of our space it is also required that the time component of the transformation, $\Lambda^0_0 \geq 1$. With this time orientation, the group is then $SO^+(1,3)$ the \textit{proper orthochronus Lorentz Group}.\\

The next logical place for us to cover is the Lie algebra of the Lorentz group, I shall assume a certain amount of knowledge of Lie algebras; however, don't worry, it won't be too in depth. For example, I won't be covering anything like Cartan Matrices, Cartan-Weyl bases, or anything other than the most basic representation theory.





% ===== Next subsection: Lie algebra of the Lorentz group =====
\subsubsection{The Lorentz Algebra:}

To begin, I will first introduce the hopefully familiar definition of a Lie algebra: 

\fbox{\begin{minipage}{34em}
\begin{definition}
    Let $G$ be a matrix Lie group, its corresponding Lie algebra, $\mathfrak{g}$, is a vector space along with the product $[\cdot, \cdot]:\mathfrak{g}\times \mathfrak{g} \rightarrow \mathfrak{g}$, called the \textit{Lie bracket}. It admits a basis of (in general) matrices, often called the \textit{generators} of the Lie algebra.
\end{definition}\end{minipage}}

To find the corresponding algebra of a Lie group, it is merely of process of linearising near the identity of the group manifold. The tangent space at the identity is imbued (it follows from the group multiplication law and the Baker-Campbell-Hausdorff formula) with an anti-symmetric, bilinear, binary operation: which is the Lie bracket. For Minkowski space with the isometry group $SO^+(1,3)$, let $\Lambda \in SO^+(1,3)$ and write an infinitesimal Lorentz transformation as
\[
\Lambda^\mu{}_{\nu} = \delta^\mu{}_{\nu} + \omega^\mu{}_{\nu} + \mathcal O(\omega^2) \,.
\]
The condition $\Lambda^T \eta \Lambda = \eta$ requires that, to first order in $\omega$,
\[
\eta_{\mu\rho}\,\omega^\rho{}_{\nu} + \eta_{\nu\rho}\,\omega^\rho{}_{\mu} = 0
\quad\Longleftrightarrow\quad
\omega_{\mu\nu} = -\,\omega_{\nu\mu}.
\]
Thus, the Lie algebra $\mathfrak{so}(1,3)$ consists of antisymmetric matrices with six independent parameters (three rotations, and three boosts). This number comes from counting free components and imposing the appropriate constraints. 


Let me now also introduce some representation theory that will be useful to know.

\vspace{0.1cm}


\fbox{\begin{minipage}{34em}
\begin{definition}
    Given a Lie group $G$, a representation of $G$ is a linear map $D: G \rightarrow GL(V)$. Where $V$ is the vector space over which the matrices act, i.e.
    \begin{equation*}
        v \mapsto D(g)v \, \in V\, ,
    \end{equation*}
    with $v \in V, \, g \in G$. $V$ is often called representation space. 
\end{definition}\end{minipage}}

Think of a representation as simply taking an element of our group and ``representing'' it with a matrix from the general linear group. There is also an analogous definition for Lie algebras. I will not cover this. In physics, the representations investigated usually cannot be split into sub-representations. It will hence be important to quickly define what I mean by this:

\fbox{\begin{minipage}{34em}
\begin{definition}
    A representation $D: G \rightarrow GL(V)$ is said to be \textit{irreducible} if it does not possess any non-trivial invariant subspaces.   
\end{definition}\end{minipage}}

The trivial invariant subspaces are $\{0\}$ and $V$ itself. \\

A common basis of generators for $\mathfrak{so}(1,3)$ is the set of generators $M^{\mu\nu}=-M^{\nu\mu}$, such that 
\[
\Lambda =\exp\left(\tfrac{1}{2}\omega_{\rho\sigma}\,
M^{\rho\sigma}\right) \,, \hspace{0.25cm} (M^{\rho\sigma})^\mu{}_{\nu} := \eta^{\rho\mu}\delta^\sigma{}_{\nu}
- \eta^{\sigma\mu}\delta^\rho{}_{\nu}.
\]
This relation between the group elements and Lie algebra elements is called the \textit{exponential map}. 

\begin{remark}
    \textit{To see this relation between group elements and algebra elements, notice that a 1-parameter family of group elements $g(t): [t_0,t] \rightarrow G$ with $g(t_0) =$ fixed can be linearised near $t_0$ via}
\begin{equation*}
    g(t_0 + \epsilon) = g(t_0) + \epsilon \underbrace{\dv{g(t)}{t}}_{X}\big|_{t=t_0} + \mathcal{O}(\epsilon^2) \, .
\end{equation*}

\textit{Given the group structure, this implies there exists a $h(\epsilon) = h(0) + \epsilon X$ with $h(0) = e$ (the identity) such that}

\begin{equation*}
    g(t_0 + \epsilon) = g(t_0)h(\epsilon) \, .
\end{equation*}

\textit{This then implies that}

\begin{equation*}
    g^{-1}(t_0)\dv{g(t)}{t}\big|_{t=t_0} = X \, .
\end{equation*}

\textit{From ODE theory, there exists a unique solution (given the initial condition of $g(t)$) such that}

\begin{equation*}
    g(t) = g(t_0)e^{(t-t_0)X} \, ,
\end{equation*}

\textit{where} 

\begin{equation*}
e(tX) : = \sum_{k=0}^\infty \frac{(tX)^k}{k!} \, .
\end{equation*}
\end{remark}


This set of generators of $\mathfrak{so}(1,3)$ satisfies the Lorentz algebra commutation relations:
\[
\
[M^{\mu\nu},\,M^{\rho\sigma}] =
\eta^{\nu\rho} M^{\mu\sigma} - \eta^{\mu\rho} M^{\nu\sigma}
- \eta^{\nu\sigma} M^{\mu\rho} + \eta^{\mu\sigma} M^{\nu\rho}\;.
\]

This basis is often split into rotations and boosts via the following relations. 

Let,
\begin{equation*}
    J_i := \tfrac12\,\epsilon_{ijk}\,M^{jk} \,(\text{rots}), \qquad
K_i := M^{0i}\, (\text{boosts})\qquad (i=1,2,3).
\end{equation*}


Then
\begin{equation*}[J_i,J_j]=\epsilon_{ijk}J_k,\qquad
[J_i,K_j]=\epsilon_{ijk}K_k,\qquad
[K_i,K_j]=-\epsilon_{ijk}J_k.
\end{equation*}

Notice that the rotational generators $J_i$ obey the same algebras as angular momentum operators in QM. This should be unsurprising. The boosts, however, do not form the same algebra. They can be made to do so by extending the field to $\mathbb{C}$, i.e. take linear combinations of vectors of the form
\begin{equation*}
    X = u + iv \, ,\hspace{0.15cm} u,v \in \mathfrak{g} \, .
\end{equation*}
This is then called the \textit{complexified lie algebra}, and denoted (for this case) $\mathfrak{so}(1,3)_{\mathbb{C}}$. Take the combinations
\begin{equation*}
A_i := \tfrac12\,(J_i + i K_i),\qquad
B_i := \tfrac12\,(J_i - i K_i)\, ,
\end{equation*}

which obey
\begin{equation*}
    [A_i,A_j]=\epsilon_{ijk}A_k,\qquad
[B_i,B_j]=\epsilon_{ijk}B_k,\qquad
[A_i,B_j]=0.
\end{equation*}


Note that I have not included the typical factor of $i$. The fact that $A$ and $B$ commute implies that the subspaces they span form an object known as an \textit{ideal} such that the total algebra can be written as the direct sum of the two sub-algebras. The sub-algebra is $\mathfrak{su}(2)_\mathbb{C}$, since it is essentially the angular momentum algebra. Thus, it is possible to write the complexified Lie algebra as 
\begin{equation*}
    \mathfrak{so}(1,3)_{\mathbb C}\;\cong\; \mathfrak{su}(2)_\mathbb{C}\;\oplus\;\mathfrak{su}(2)_\mathbb{C}.
\end{equation*}

Note that it is the complexified version of $\mathfrak{su}(2)$ as we are taking complex linear combinations of the form 
$X = u + iv$, as described earlier. I will now take a brief detour to introduce some `highest weight theory'. But, firstly I must use an important relation, namely the fact that 

\begin{equation*}
    \mathfrak{sl}(2, \mathbb{C}) \cong \mathfrak{su}(2)_\mathbb{C} \, .
\end{equation*}

I shall quickly prove this. 

\begin{proposition}
    The complexified Lie algebra $\mathfrak{su}(2)_\mathbb{C}$ is isomorphic to the algebra $\mathfrak{sl}(2, \mathbb{C})$. 
\end{proposition}

\begin{proof}
    To show that there exists an isomorphism, it must be shown that there exists a bijection between the algebras. By $\mathfrak{su}(2)_\mathbb{C}$ it is meant:

    \begin{equation*}
        \mathfrak{su}(2)_\mathbb{C} = \mathfrak{su}(2) \otimes_\mathbb{R}\mathbb{C} 
    \end{equation*}
    Now, I want to construct a  bijection (injective and surjective) between the two sets. I shall define the map $\eta : \mathfrak{su}(2)_\mathbb{C} \rightarrow \mathfrak{sl}(2,\mathbb{C})$ by

    \begin{align*}
        \eta\left(\sum_{k =1}^N X_k \otimes z_k\right) \mapsto \sum_{k=1}^N z_kX_k \, \, , \, X \in \mathfrak{su}(2), \, z_k \in \mathbb{C} \, ,
    \end{align*}
for some finite $N$. This map is $\mathbb{R}$-linear in the first argument (since $\mathfrak{su}(2)$ is a real vector space) and $\mathbb{C}$-linear in the second, i.e. 

\begin{align*}
    \eta((aX + bY) \otimes z) & = z(aX + bY) \qquad a,b \in \mathbb{R}, \hspace{0.15cm} X,Y \in \mathfrak{su}(2),\hspace{0.15cm} z \in \mathbb{C} \\
    \eta(X \otimes (z+w)) & = (z+w) X \qquad z,w \in \mathbb{C}, \hspace{0.15cm} X \in \mathfrak{su}(2) \, .
\end{align*}

For it to be a valid Lie algebra isomorphism, it must preserve the Lie bracket: let's check,

\begin{align*}
    \eta\left(\left[\sum_{k=1}^N X_k \otimes z_k, \sum_{j=1}^N Y_j \otimes w_j\right]  \right) & = \eta \left( \sum_{k=1}^N\sum_{j=1}^N \left[X_k, Y_j \right] \otimes z_kw_j\right)\\
    & = \sum_{k=1}^N\sum_{j=1}^N z_kw_j[X_k,Y_j]\\
    & = \sum_{k=1}^N z_k[X_k, \sum_{j=1}^N w_jY_j]\\
    & = \left[\sum_{k=1}^N z_k X_k, \sum_{j=1}^N w_jY_j \right]\\
    & = \left[\eta\left(\sum_{k=1}^N X_k \otimes z_k\right), \eta\left(\sum_{j=1}^N Y_j \otimes w_j\right)\right] \, ,
\end{align*}

thus, it is a valid Lie algebra isomorphism. I will now show injectivity and surjectivity. For a linear isomorphism, injectivity requires that 
\begin{equation*}
    \ker(\eta) = \{0\} \, .
\end{equation*}

I choose the basis $\{T_a\}_{a=1}^3$ for $\mathfrak{su}(2)$ with complexification $\{T_a \otimes 1\}_{a = 1}^3 \in\mathfrak{su}(2)_\mathbb{C}$. A general element of $\mathfrak{su}(2)_\mathbb{C}$ can be written as

\begin{equation*}
    X = \sum_{k=1}^3 z_k(T_k \otimes1) \, ,
\end{equation*}
thus

\begin{equation*}
    \eta(X) = 0 \iff \sum_{k=1}^3 z_kT_k = 0\, , 
\end{equation*}
but since $T_k$ are linearly independent, this equality implies $z_k = 0 \hspace{0.15cm} \forall  \, k \, .$ Using this,

\begin{equation*}
    X = \sum_{k=1}^3 z_k(T_k \otimes 1) = \sum_{k=1}^3 0(T_k \otimes 1) = 0 \, .
\end{equation*}

Hence, the kernel of $\eta$ is the singleton $\{0\}$, as required. Surjectivity follows since $\eta$ is a $\mathbb{C}$-linear map between spaces of equal dimension.
\end{proof}



\fbox{\begin{minipage}{34em}
\begin{definition}
The Lie algebra $\mathfrak{sl}(2,\mathbb{C})$ is generated by $\{H,E_{\pm}\}$ with
\[
[H,E_{\pm}] = \pm2E_\pm, \qquad [E_+, E_-] = H.
\]
A representation of  $\mathfrak{sl}(2, \mathbb{C})$ is said to be of \emph{highest weight} $\ell$
if there exists a non-zero vector $v_0 \in V$ (the rep space) such that
\[
H v_m = m v_m, \qquad E_- v_0 = 0, \qquad E_+ v_\ell = 0,
\]
and $V$ is spanned by repeated applications of $E_+$:
\[
v_k := (E_+)^k v_0, \quad k=0,1,\dots,\ell.
\]
$v_\ell$ is then called the highest weight state. For $\ell \in \mathbb{N}$, this construction yields a finite--dimensional irreducible representation
of dimension $\ell+1$. Every finite--dimensional irreducible representation of $\mathfrak{sl}(2, \mathbb{C})$
arises in this way.
\end{definition}\end{minipage}}


Given these facts, it is possible to write the two distinct sets of spin-quantum numbers of the two algebras in $\mathfrak{so}(1,3)_\mathbb{C} = \mathfrak{sl}(2, \mathbb{C}) \oplus \mathfrak{sl}(2, \mathbb{C})$ as $(j_L, j_R)$. In physics, it is common to define $j_L/ j_R = \frac{\ell_{L/R}}{2}$. These numbers encode differing representations of the Lorentz group. 


The Lorentz group is actually what's known as \text{non-compact} (imagine infinite volume); thus, it can be shown (take my word for it) that there exist no non-trivial finite-dimensional unitary representations. This is bad for any quantum theory since it is required that our theories be unitary. This means that particles can't be described with this alone; the group needed is the \textit{Poincar\'e} group (more precisely, a unitary representation of it). \\

The Poincar\'e group is the Lorentz group $+$ translations (technically, it is a semi-direct product group; but I won't worry about that here), with single particle states being described by unitary irreducible reps. of the Poincar\'e group. They are indexed by both spin and mass. This topic is slightly beyond the main aim of this text; it is, however, very interesting, so I suggest reading further about it. 

\subsubsection{Representations of the Lorentz Group:}

I shall now quickly look at certain representations of the Lorentz group i.e. different values of $(j_L,j_R)$:

\begin{itemize}
    \item $(0,0)$ - This representation is the called the scalar representation. It is not very interesting. In terms of Lie theory it is called the trivial representation. These representations are carried by scalar field theories. 
    \item $(1/2,0)$ and $(0,1/2)$ - These are the left and right handed Weyl spinor representations. They are useful in supersymmetric theories. 
    \item $(1/2,1/2)$ - This is the vector representation of the Lorentz group. Some objects that transform under this representation are 4-position $x_\mu$, derivatives $\partial_\mu$, and the 4-momentum $p_\mu$, along with others. 
\end{itemize}
        These representations are only a few of the many allowed possibilities. In terms of field theories that have multiple different types of field e.g. imagine having a scalar field including an interaction term which involves a vector field like $A_\mu$, the fields live in different representation spaces of the Lorentz group (technically the full Poincar\'e group), hence, transform under separate representations. Let's look quickly at the scalar representation to hopefully make this more concrete. A scalar is simply a 1$\times$1 matrix, hence, our representation would be $D: SO^+(1,3) \rightarrow GL(1,\mathbb{C})$. Now, it should hopefully be clear to see that $GL(1,\mathbb{C}) \cong \mathbb{C}^\times$. With this, it turns out that the only representation that is 1-dimensional and continuous for this group is the trivial one (such that all elements of $G$ map to the identity of $GL(n, V)$). Thus, $D(\Lambda) = 1 \, ,\, \forall \, \Lambda. $ This is exactly how scalar fields transform in QFT (i.e. the field is unchanged under Lorentz transformations). So, if you want to sound clever, simply say that a scalar field transforms under the trivial representation of the Lorentz (actually Poincar\'e) group.

\section{4-Vectors and Dynamics:}

Now that I have covered the group theory of the Lorentz group, let's now actually look at some relativistic dynamics. Note, being as terrible with constants as I am, I shall use natural units: I set $c = 1$. With this choice of units, Einstein's famous relation is now just $E = m$. This is often the case in most theory texts as it makes things a lot cleaner. It can, however, lead to issues if you forget to put them back, when all said and done. 


\subsection{4-Vectors:}

Given our Minkowski space $\mathbb{R}^{1,3}$ a point on the manifold is called an event or 4-position and (as stated earlier) takes the form $x^\mu = (t,x^1,x^2,x^3)$. As you know, time in relativity is relative. Hence, it would not make sense to define the usual things like velocity or acceleration using the regular coordinate time. This would mean that the velocity of an object would be frame dependent; i.e., a race-car could be one velocity for the driver and another velocity for an observer. I instead use something called the proper time, which I shall now introduce:

\fbox{\begin{minipage}{34em}
\begin{definition}
 A \textit{world-line} is the curve $\Gamma: I \subset \mathbb{R} \rightarrow \mathbb{R}^{1,3}$. It is said to be \textit{timelike} if $\eta_{\mu\nu}\dot{\Gamma}^\mu \dot{\Gamma}^\nu <0\, , \forall \, t \in I$.
\end{definition}\end{minipage}}

Given such a world-line, the proper time is simply the actual length of the curve. Which is invariant. 

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{proper time} $\tau
    : I \rightarrow J \subset \mathbb{R}$ is given by the arc length along the curve $\Gamma$,

    \begin{equation*}
        \tau(t) = \int_{t_0}^t \, ds \, \sqrt{-\eta_{\mu \nu}\dot{\Gamma}^\mu(s) \dot{\Gamma}^\nu(s)} \, .
    \end{equation*}
\end{definition}\end{minipage}}
The normalisation $\eta_{\mu \nu}\dot{\Gamma}^\mu(\tau) \dot{\Gamma}^\nu(\tau) = -1$ is often used. This then means that the curve $\Gamma$ is parametrised by the proper time. With this, the 4-velocity of the curve can now be defined (imagine a particle whose position is dependent on time).

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{4-velocity} of a timelike curve $\Gamma$ is simply

    \begin{equation*}
        U^\mu = \pdv{\Gamma^\mu(\tau)}{\tau} = \pdv{(t(\tau), x^1(\tau), x^2(\tau), x^3(\tau))}{\tau} \, .
    \end{equation*}

    Where I have used local coordinates to describe the curve $\Gamma$. 
\end{definition}\end{minipage}}

The rate of change of coordinate time with respect to the proper time is a special factor: called the Lorentz factor, $\gamma$. It encodes how much coordinate time, $t$, differs from the proper time, $\tau$. Let's use the normalisation condition,

\begin{align*}
    -1 & = -(U^0)^2 + \norm{\boldsymbol{U}}^2 \\
    & = -(U^0)^2+|U^0|^2\norm{\boldsymbol{v}}^2 \\
    \implies 1 & = (U^0)^2 \left(1 - \norm{\boldsymbol{v}}^2\right) \\
    \implies U^0 & = \frac{1}{\sqrt{1 - \norm{\boldsymbol{v}}^2}} =\gamma \, .
\end{align*}
Just as I have defined the 4-velocity, I am free to define the 4-acceleration:

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{4-acceleration} of a timelike curve $\Gamma$ is simply

    \begin{equation*}
        A^\mu = \pdv{U^\mu(\tau)}{\tau} \, .
    \end{equation*}
\end{definition}\end{minipage}}


Given the normalisation condition on the 4-velocity, it is clear 
\begin{align*}
   \pdv{}{\tau} \left(\eta_{\mu \nu} U^\mu U^\nu \right) & = 0, \\
   \implies \eta_{\mu \nu}U^\mu A^\nu & = 0\, .
\end{align*}

This then implies the 4-velocity and 4-acceleration are orthogonal. This means essentially that the 4-acceleration is purely spatial. To see this, swap to a simple rest frame of the particle and use the orthogonality condition to find that the timelike component of $A$ is 0.

\subsubsection{Curves of Extremal Proper Time:}
I hope you're familiar with the action functional and the concept that the equations of motion come from extremising  said action. Essentially, in this case, I am looking for a curve such that $\delta \tau= 0$. \\


Let's look at how this would work if I vary the proper time $\tau[t]$ with respect to the curve $\Gamma(s)$. To do this, I need to use functional calculus. Just treat it the same as regular calculus, but now the objects of interest are functions of functions. 

\begin{align*}
    \tau[t]  & = \int \, \text{d}s \, \sqrt{-\eta_{\mu \nu}\dot{\Gamma}^\mu(s)\dot{\Gamma}^\nu(s)}\\
    \frac{\delta \tau}{\delta \dot{\Gamma}^\beta(\sigma)} & = \int \,\text{d}s \frac{1}{\sqrt{-\eta_{\mu \nu}\dot{\Gamma}^\mu(s)\dot{\Gamma}^\nu(s)}} \cdot \delta^\nu_\beta \, \eta_{\mu \nu} \dot{\Gamma}^\mu(s) \delta(s - \sigma) \\
    \frac{\delta \tau}{\delta \dot{\Gamma}^\beta(\sigma)} & = \frac{1}{\sqrt{-\eta_{\mu \nu}\dot{\Gamma}^\mu(\sigma)\dot{\Gamma}^\nu(\sigma)}} \cdot \dot{\Gamma}_\beta(\sigma)\, .
\end{align*}

Similar to finding the extrema in regular calculus I demand that the variation, $\delta\tau = 0$. Thus, using the Euler-Lagrange equations, I find

\begin{align*}
    \pdv{}{\sigma}\left(\frac{1}{\sqrt{-\eta_{\mu \nu}\dot{\Gamma}^\mu(\sigma)\dot{\Gamma}^\nu(\sigma)}} \cdot \dot{\Gamma}_\beta(\sigma) \right) & = 0 \\
    \implies \ddot{\Gamma}_\beta(\sigma) & = 0 \, .
\end{align*}
where the derivative of the square root vanished due to the normalisation condition $\eta_{\mu \nu}\dot{\Gamma}^\mu(\tau) \dot{\Gamma}^\nu(\tau) = -1$. Since, for a timelike curve, I am free to set $\sigma = \tau$, I have (raising the index) 

\begin{equation*}
    \ddot{\Gamma}^\mu(\tau) = 0 \implies \Gamma^\mu(\tau) =  a^\mu \tau + b^\mu\, .
\end{equation*}

This means that curves are straight lines (affinely parametrised): i.e., particles follow straight paths, at least for flat space. Note, this equation can also be derived from the action functional of a relativistic particle.\\



\subsection{Energy-Momentum relations:}

You are probably aware that energy and momentum
are often combined into a single tensor (along with shear and pressure): the Energy-momentum tensor, $T_{\mu \nu}$. In special relativity (i.e. ignoring any curvature) this can be defined as follows:

\fbox{\begin{minipage}{34em}
\begin{definition}
    The \textit{Energy-Momentum} tensor of a Lagrangian density $\mathcal{L}$, which is dependent on the fields $\phi_a$, $a = 1, \cdots, n$, and their derivatives, is 

    \begin{equation*}
      T^\mu_\nu = \frac{\partial \mathcal{L}}{\partial(\partial_\mu\phi_a)} \partial_\nu \phi_a - \delta^\mu_\nu \mathcal{L} \, .
    \end{equation*}
\end{definition}\end{minipage}}

Let's look at the case where I have a relativistic point particle of mass $m$ parametrised by $\tau$, and localised at a point $y$. In this case, the energy-momentum tensor is,

\begin{equation*}
    T^{\mu\nu} = m \int \text{d}\tau \, \, U^\mu(\tau)U^\nu(\tau) \delta^4(x - y(\tau))\, .
\end{equation*}

It is a distribution with support along the world-line parametrised by $\tau$. Using the energy-momentum tensor, I am able to form the 4-momentum,

\fbox{\begin{minipage}{34em}
\begin{definition}
Given a stress-energy tensor $T^{\mu\nu}(x)$ on Minkowski space,
the total \textit{4-momentum} of a localized system at time $t$ is
\[
P^\nu(t) := \int_{\Sigma_t} T^{0\nu}(t,\boldsymbol{x})\,d^3x,
\]
where $\Sigma_t=\{(t,\boldsymbol{x})\,|\,\boldsymbol{x}\in\mathbb{R}^3\}$ is a constant-time
hypersurface. In particular,
\[
E= P^0=\int_{\Sigma_t} T^{00}\,\text{d}^3 x,\qquad
P^i=\int_{\Sigma_t} T^{0i}\,\text{d}^3x 
 \, .
\]
\end{definition}\end{minipage}}

With this definition, it becomes possible to compute the corresponding 4-momentum for the energy-momentum tensor written above, via
\begin{align*}
    E & = \int_{\mathbb{R
    }^3} \text{d}^3x \, \, T^{00} \\
    & = m \int_{\mathbb{R}^3} \int \text{d}^3x \, \text{d} \tau \, \, U^0 U^0 \delta (t
    - y^0(\tau)) \delta^3(\boldsymbol{x} - \boldsymbol{y}(\tau))\\
    & = m \int_{\mathbb{R}^3} \text{d}^3 x \, \text{d}\tau \, \frac{\delta(\tau -\tau^\prime)}{\left| \dv{y^0(\tau^\prime)}{\tau}\right|} U^0U^0 \delta^3(\boldsymbol{x} - \boldsymbol{y}(\tau)) \ \\
    & = m U^0 = m \gamma \, ,
\end{align*}

where $\tau^\prime$ is a root of the function $f(\tau) = t - x^0(\tau)$. Via a similar computation, the 3-momentum is $P^i = mU^i = \gamma m v^i$ (check yourself). \\


Notice that the inner product of the 4-momentum is, 

\begin{equation*}
    P^\mu P_\mu = -E^2 + \norm{\boldsymbol{p}}^2 \, .
\end{equation*}

Now, what is $P^\mu P_\mu$? Let's see.

\begin{proposition}[Mass shell condition]
The 4-momentum $P^\mu$ of a particle of rest mass $m$ satisfies
\[
\eta_{\mu\nu} P^\mu P^\nu = -m^2 .
\]
\end{proposition}

\begin{proof}
For a point particle $P^\mu = m U^\mu$ with $U^\mu=\tfrac{dx^\mu}{d\tau}$.
Since the 4-velocity is normalized $\eta_{\mu\nu} U^\mu U^\nu = -1$, it follows that
\[
P_\mu P^\mu = m^2 \, U_\mu U^\mu = -m^2 .
\]
\end{proof}

Thus, note that the inner product is 

\begin{equation*}
    E^2 = m^2 + \norm{\boldsymbol{p}}^2 \, . 
\end{equation*}
Which is the famous relation (for the rest frame of the particle, where $\boldsymbol{p}$ is zero). For particles that do not obey the normalization condition, for example, virtual particles, the mass-shell condition does not hold. These particles are said to be \textit{off-shell}. As this quantity is a Lorentz scalar, it is clearly invariant under Lorentz transformations (check this). \\

In the massless limit $P_\mu P^\mu = 0$. This is due to the fact that, for a null world-line, $\eta_{\mu \nu}k^\mu k^\nu = 0$, where $k^\mu$ is the tangent vector to the curve. Which is parametrised by an arbitrary affine parameter, since the proper time does not exist.

\subsection{The Centre of Momentum Frame:}

A convenient frame of reference to use in particle collisions is the \textit{centre of momentum frame}. 

\fbox{\begin{minipage}{34em}
\begin{definition}
Suppose I have $n$ particles each with an associated 3-momentum $\boldsymbol{p}_n$, then the \textit{centre of momentum frame} is the inertial frame such that,

\begin{equation*}
    \boldsymbol{p}_\text{tot} = \sum_n \boldsymbol{p}_n = 0 \, .
\end{equation*}
\end{definition}\end{minipage}}

In such a frame, the norm of the total 3-momentum is clearly zero. Hence, for a collection of particles, the centre of momentum frame is also the rest frame. This frame is useful in multi-particle collisions since the sum of all momenta can be set to zero thereby simplifying analysis. While it is good to know that it exists, it does not come up (I think at all) in the courses you wish to read.

\section{Some Classical Electrodynamics:}

The theory of Electrodynamics is one of the great theories of classical physics, formulated by the brilliant James Clerk Maxwell. It was, in fact, the first fully relativistic theory. Before Einstein's own theory. This is due to the formulation requiring that the speed of light be constant for all observers. This suggested, at the time, the existence of an ``aether". Thus, explaining the need for the famous Michelson–Morley experiment. This issue was then later resolved by Einstein. His theory eliminated the need for an aether and showed that the invariance of the speed of light is a fundamental principle of nature.
\subsection{Maxwell Theory:}

To discuss classical Electrodynamics, I must first discuss Maxwell's theory of electromagnetism. As well as its gauge symmetries. 


\fbox{\begin{minipage}{34em}
\begin{definition}
\textit{Maxwell's Equations} are the following set of PDEs for the electric field 
$\boldsymbol{E}$ and magnetic field $\boldsymbol{B}$:

\begin{align*}
    \nabla \cdot \boldsymbol{E} & = \rho, & \nabla\cdot \boldsymbol{B} & = 0, \\
    \nabla \times \boldsymbol{E} & = - \pdv{\boldsymbol{B}}{t}, & \nabla \times \boldsymbol{B} & = \boldsymbol{J} + \pdv{\boldsymbol{E}}{t} \, ,
\end{align*}
where I have set $\varepsilon_0 = \mu_0 = 1$.
\end{definition}\end{minipage}}

The divergence relation for the $\boldsymbol{B}$ field famously says there exists \textit{no magnetic monopoles}. This, however, disagrees with Dirac's famous quantization condition: which states that the quantization of the electric charge can be explained exactly if there were to exist a single monopole. There has, of course, never been any monopole detected. Despite this, Dirac's theoretical explanation remains the most widely accepted for providing a reason to why the electric charge is quantized. \\

From general definitions in vector calculus it is clear that the combination $\nabla \cdot (\nabla \times \boldsymbol{X}) = 0$. If you want to see this explicitly, write it in index notation and, assuming $\boldsymbol{X}$ is sufficiently smooth, notice that due to the anti-symmetry in the cross product and symmetry in partials, the total must be zero. This insight allows us to write $\mathbf{B}$ in terms of a more fundamental object, the magnetic potential $\boldsymbol{A}$, as 

\begin{equation*}
    \boldsymbol{B} = \nabla \times \boldsymbol{A} \, .
\end{equation*}

Similarly, the Electric field can be written as

\begin{equation*}
    \boldsymbol{E} = -\nabla\phi - \pdv{\boldsymbol{A}}{t} \, .
\end{equation*}

The $\phi$ term is the electric potential. It is a scalar field, similar in nature to the formulation of force in terms of the potential energy, $\boldsymbol{F} = -\nabla U$. I can actually package it all up neatly into a single 4-vector, the \textit{Gauge potential}, 

\begin{equation*}
    A^\mu = (\phi, \boldsymbol{A}) \, .
\end{equation*}

It is called this since it is the prototypical example of a gauge theory. In fact, all gauge theories follow essentially the same logic as EM. Now, a gauge is merely a redundancy in our description. The underlying physics should not depend on the choice of gauge. Think, as an example, of a weighing scale. It does not matter whether I assign a function to measure the weight of someone in Kg or lbs, the underlying physical laws should remain unchanged. This is to say that the ``observables'' of the theory (things that can be actually measured in the lab) have to be gauge invariant. I should emphasize that a gauge transformation is \textit{not} a symmetry.  It is a redefinition of the fields themselves. \\

In this manner, the gauge potential is not unique. It is possible to add a smoothly differentiable function $\omega(t,\boldsymbol{x})$, such that

\begin{align*}
    A^\mu \rightarrow A^\mu + \partial^\mu \omega \, ,
\end{align*}

where 
\begin{equation*}
    \partial^\mu = (-\partial_t, \nabla) \, ,
\end{equation*}
is the 4-derivative. Does this transformation really leave the physics unchanged? Well, yes. I will quickly show this.

\begin{proposition}
    Both the $\boldsymbol{E}$ and $\boldsymbol{B}$ fields are unchanged under this (gauge) transformation.
\end{proposition}

\begin{proof}
    Under the transformation
    \begin{equation*}
        A^\mu \rightarrow A^{\prime \mu} = A^\mu + \partial^\mu \omega \, ,
    \end{equation*}
   note that the $\boldsymbol{E}$ field transforms as 
    \begin{align*}
        \boldsymbol{E} \rightarrow \boldsymbol{E}^\prime & = -\nabla(\phi - \partial_t \omega) - \partial_t(\boldsymbol{A} +\nabla\omega)\\
        & = -\nabla\phi - \partial_t\boldsymbol{A} + \cancel{\partial_t(\nabla\omega - \nabla\omega)}\\
        & = \boldsymbol{E}\,.
    \end{align*}
    It is a similar story for the $\boldsymbol{B}$ field; it transforms as 
    \begin{align*}
        \boldsymbol{B} \rightarrow \boldsymbol{B}^\prime & = \nabla \times (\boldsymbol{A} + \nabla\omega) \\
        & = \nabla \times \boldsymbol{A} + (\nabla \times \nabla \omega)\\
        \implies \boldsymbol{B} & = \boldsymbol{B}^\prime \, ,
    \end{align*}
    since $\nabla \times \nabla\omega = 0$.
\end{proof}


This is good! The things  actually measured using an EMF devices, for example, are completely gauge invariant. This redundancy makes it possible to \textit{choose a gauge}. Certain gauges will make calculations much simpler. Common gauge include:

\begin{itemize}
    \item The \textit{Lorenz Gauge}, 
           \begin{equation*}
               \partial_\mu A^\mu = 0 .
           \end{equation*}
           It is always possible choose this gauge; to see this, notice that, given a gauge field $A^{\prime \mu}$, such that $\partial_\mu A^{\prime \mu} = f(t, \boldsymbol{x})$, $\omega$ can be chosen such that
           \begin{equation*}
               \partial_\mu \partial^\mu \omega = -f \, .
           \end{equation*}
           The gauge potential is then
           \begin{equation*}
               A^\mu = A^{\prime \mu} + \partial^\mu \omega,
           \end{equation*}
           with $\partial_\mu A^\mu = 0.$ These equations always have solutions. The Lorenz gauge has the advantage that it is Loren\textbf{t}z invariant.
    \item The \textit{Coulomb Gauge},
    \begin{equation*}
        \nabla \cdot \boldsymbol{A} = 0.
    \end{equation*}
    It is possible to choose this gauge using the same argument as for the Lorenz gauge. It turns out that the $A_0$ component is purely specified by $\nabla \cdot \boldsymbol{A}$; set 
    \begin{equation*}
        A_0 = 0\, .
    \end{equation*}
    This condition is called the \textit{temporal gauge}. In general the Coulomb gauge requires $A_0 =$ fixed, by Gauss's Law. The remaining three components of $A^\mu$ satisfy one constraint leaving only two degrees of freedom (dof). In terms of EM theory, these two dof align with the two polarisation states of the photon. Sadly, unlike the Lorenz gauge, the Coulomb gauge is not Lorentz invariant. 
\end{itemize}\\


Within field theory it is typical to package the Electric and magnetic fields into a single object defined as follows:

\fbox{\begin{minipage}{34em}
\begin{definition}
The \textit{Field-Strength tensor} is an anti-symmetric (2,0) tensor field, written in terms of the gauge potential as 

\begin{equation*}
    F^{\mu \nu} = \partial^\mu A^\nu - \partial^\nu A^\mu \, .
\end{equation*}
\end{definition}\end{minipage}}


It should be clear to see that this tensor is completely gauge invariant (please check yourself). How can this tensor be written in terms of $\boldsymbol{E}$ and $\boldsymbol{B}$? Notice that 

\begin{align*}
    F^{\mu}_\mu := F^{\mu \nu}\eta_{\mu \nu} & = (\partial^\mu A^\nu - \partial^\nu A^\mu)\eta_{\mu \nu}\\
    & = \partial^\mu A_\mu - \partial^\nu A_\nu \\
    & = 0 \, .
\end{align*}

This means that the trace is zero. Looking at the off-diagonal elements, it is clear

\begin{align*}
    F^{0i} & = \partial^0 A^i - \partial^i A^0 \\
    & = -\partial_t A^i -\partial^i \phi \\
    & = E^i \, .
\end{align*}

From anti-symmetry, it is clear that

\begin{equation*}
    F^{i0} = - F^{0i} = -E^i \, .
\end{equation*}

Now, looking at the next row it is clear

\begin{equation*}
    F^{1i} = \partial^1 A^i - \partial^i A^1 \, , 
\end{equation*}

where $i = 2,3$ as the first element is determined from $F^{10}$ and $F^{11} = 0$ from the trace condition. With this, notice 

\begin{align*}
    F^{12} & = \partial^1 A^2 - \partial^2 A^1\\
    & = \epsilon_{ij3}\partial^i A^j\\
    & = (\nabla\times \mathbf{A})^3 = B_3 = B_z \, .
\end{align*}

Similarly, due to anti-symmetry,

\begin{equation*}
    F^{21} = -B_z \, .
\end{equation*}

Using essentially the same argument for the remaining components, (convince yourself) it is found that


\begin{equation*}
    F^{\mu\nu} =
 \begin{pmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & B_z & -B_y \\
-E_y & -B_z & 0 & B_x \\
-E_z & B_y & -B_x & 0
 \end{pmatrix} \, .
\end{equation*}

Maxwell's equations can then be written neatly in terms of $F^{\mu \nu}$ via the introduction of a \textit{4-current},

\begin{equation*}
    J^\mu = (\rho, \boldsymbol{J}) \, ,
\end{equation*}

such that 
\begin{equation*}
    \partial_\nu F^{\mu \nu}  = J^\mu\,.
\end{equation*}

Notice, however, that $F^{\mu \nu}$ satisfies 

\begin{equation*}
    \partial_\mu \partial_\nu F^{\mu \nu} = 0 \, .
\end{equation*}

Thus the 4-current must satisfy the continuity condition

\begin{equation*}
    \partial_t\rho +\nabla\cdot \boldsymbol{J} = 0 \, .
\end{equation*}

Written another way, this implies 

\begin{equation*}
    \partial_\mu J^\mu = 0.
\end{equation*}

A current that satisfies this is said to be \textit{conserved}. This relation can be derived more thoroughly from, arguably, the most important theorem in physics: Noether's Theorem. I wont cover Noether's theorem here as it is covered extensively and excellently in David Tong's \href{https://www.damtp.cam.ac.uk/user/tong/qft/qft.pdf}{lecture notes} on QFT. But, it essentially boils down to the following,
\begin{equation*}
    \textit{Continuous Symmetry} \implies \textit{Conserved Current} \, .
\end{equation*}


Note, this is not a two way relation, i.e. the converse is not always true. Also, this relation only holds classically and on-shell. In the quantum theory, classically conserved currents can acquire \textit{anomalies}. \\

For the remaining Maxwell equations, use something called the \textit{Bianchi Identity} to write them as 

\begin{equation*}
    \partial_{[\mu}F_{\nu \rho]} = 0 \, .
\end{equation*}





\subsection{EM is a Lorentz Covariant Theory:}

As I alluded to earlier, the theory of Electromagnetism is a relativistic theory. This becomes obvious once the gauge potential and field-strength tensor are introduced. This is because they transform naturally under Lorentz transformations. For example, the gauge potential transforms as 

\begin{equation*}
    A_\mu \rightarrow A^{\prime}_{\mu} = (\Lambda^{-1})_\mu^\nu A_\nu \, .
\end{equation*}

In the language of representation theory, I would say it transforms under the vector (sometimes called \textit{defining}) rep of $SO^+(1,3)$. 

\begin{remark}
    \textit{If you want the formal reason for this, it is because the gauge potential is a 1-form, so can be written as}
    \begin{equation*}
        A = A_\mu dx^\mu \, ,
    \end{equation*}
    \textit{where $dx^\mu$ is a dual basis (of 1-forms). It transforms as} 
    \begin{equation*}
        dx^\mu \rightarrow \Lambda^\mu_\nu dx^\nu \, ,
    \end{equation*}
    \textit{hence, as $A$ is a coordinate independent object, $A_\mu$ must transform as}

    \begin{equation*}
        A \rightarrow (\Lambda^{-1})^\mu_\nu A_\mu \, .
    \end{equation*}
    \textit{which is the manner described above (after renaming dummy indices).}
\end{remark}

Now, in a similar fashion, the field-strength tensor also transforms under Lorentz transformations. But not in the same way. The field-strength is best understood as the 2-form 

\begin{equation*}
    F = \frac{1}{2}F_{\mu \nu} \, \text{d}x^\mu \wedge\text{d}x^\nu \, ,
\end{equation*}

with 

\begin{equation*}
    F_{\mu \nu} : = F(\partial_\mu, \partial_\nu) \, ,
\end{equation*}

where $\partial_\mu$ is a basis for the tangent space. Under a Lorentz transformation, it transforms as 

\begin{equation*}
   F_{\mu \nu} \rightarrow (\Lambda^{-1})_\mu^\sigma F_{\sigma \rho} (\Lambda^{-1})_\nu^\rho \, ,
\end{equation*}

while it's contravariant form transforms via

\begin{equation*}
    F^{\mu \nu} \rightarrow F^{\prime \mu \nu} = \Lambda^\mu_\rho F^{\rho \eta}\Lambda_\eta^\nu \,.  
\end{equation*}

Given that these objects transform under Lorentz transformations, it is possible to form Lorentz invariant quantities. Which is great when building field theories. Since the Lagrangian densities (and hence actions) built should be completely Lorentz invariant. This fact also constrains the form of the action to Lorentz invariants built from the field-strength. \\

It is likely best too see and example. One common Lagrangian seen in QFT is given by, 

\begin{equation*}
    \mathcal{L} = F_{\mu \nu}F^{\mu \nu} \, .
\end{equation*}

This quantity is a Lorentz scalar, which is exactly what is needed. This is the Lagrangian density used in QED (up to constants).


\section{Conclusion:}

These are essentially all the tools you need to jump straight into QFT and possibly AQFT if you're feeling brave. There is, of course, many things that I have left out of these notes to avoid bloat. But, this is about all the material you need to be in line with the requirements given on the Part III webpage. To test your understanding, I suggest doing this \href{https://www.maths.cam.ac.uk/postgrad/part-iii/files/misc/grspecialrelativity.pdf}{exercise sheet} for fun.

\end{document}
